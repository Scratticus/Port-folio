{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_stemmatizer(text_series):\n",
    "    \"\"\"\n",
    "    This function preprocesses a pandas Series of sentences, typically taken from a dataframe column and prepares them for classification/regression modelling\n",
    "    by tokenizing, removing stop words, and stemmatizing the series.\n",
    "    \n",
    "    Args:\n",
    "    text_series (pd.Series): Input pandas Series containing sentences.\n",
    "    \n",
    "    Returns:\n",
    "    pd.Series: Processed Series containing stemmed words.\n",
    "\n",
    "    Example:\n",
    "    df['to_be_stemmed'] = pd.Series({0: 'I like this', 1: 'good times'})\n",
    "    df['stems'] = column_stemmatizer(df['to_be_stemmed'])\n",
    "\n",
    "    returns:\n",
    "    df['stems'] = pd.Series({0: ['like', 'this'], 1: ['good', 'time']})\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import nltk\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.stem.snowball import EnglishStemmer\n",
    "    from nltk.tokenize.regexp import RegexpTokenizer\n",
    "\n",
    "    # Download NLTK resources\n",
    "    if not nltk.corpus.stopwords.fileids():\n",
    "        nltk.download('punkt')\n",
    "        nltk.download('stopwords')\n",
    "\n",
    "    # Initialize stemmer, stopwords and regex tokenizer\n",
    "    stemmer = EnglishStemmer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokenizer = RegexpTokenizer(r'[\\w]+')\n",
    "\n",
    "    # prepare list to hold returned data\n",
    "    stemmed_cells = []\n",
    "\n",
    "    # Loop through columns:\n",
    "    for i in text_series:\n",
    "\n",
    "        # Tokenize series and set lower case\n",
    "        tokens = tokenizer.tokenize(i.lower())\n",
    "\n",
    "        # remove stopwords\n",
    "        stopped = []\n",
    "        for token in tokens:\n",
    "            if token not in stop_words:\n",
    "                stopped.append(token)\n",
    "        \n",
    "        stemmed = ''\n",
    "        for word in stopped:\n",
    "            stemmed_word = stemmer.stem(word)\n",
    "            stemmed += stemmed_word + ' '\n",
    "        \n",
    "        stemmed.strip()\n",
    "\n",
    "        stemmed_cells.append(stemmed)\n",
    "\n",
    "    stemmed_series = pd.Series(stemmed_cells)\n",
    "\n",
    "    return stemmed_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    favourit thing harri potter hermion granger 5 ...\n",
      "1                     love lord ring movi book justic \n",
      "2                    wish never seen looper load shit \n",
      "3                                      like good time \n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test1 = pd.Series({\n",
    "    0: \"My favourite thing about Harry Potter is hermione Granger 5 stars!\",\n",
    "    1: \"I love lord of the rings, but this movie didn't do the books justice\",\n",
    "    2: \"I wish I had never seen looper, what a load of shit\",\n",
    "    3: \"I like this, good times\"\n",
    "    })\n",
    "\n",
    "test1_return = column_stemmatizer(test1)\n",
    "\n",
    "print(test1_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    favorit book android dream electr sheep \n",
      "1                        arriv 1 00pm 4 30pm \n",
      "2                            special charact \n",
      "3                                worri happi \n",
      "4                    exampl sentenc punctuat \n",
      "5                               12345 number \n",
      "6                                 beauti day \n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "test2_data = ({\n",
    "    'test_text': [\n",
    "        \"My favorite book is 'Do android's dream of Electric Sheep'.\",\n",
    "        \"I'll arrive between 1.00pm and 4.30pm.\",\n",
    "        \"These are special characters #%^$@*&$#&^$\",\n",
    "        \"Don't worry, be happy!\",\n",
    "        \"This is just - an example, sentence with some; punctuation.\",\n",
    "        \"12345 is a number.\",\n",
    "        \"It's a beautiful day.\",\n",
    "        ]\n",
    "    })\n",
    "\n",
    "test2 = pd.DataFrame(test2_data)\n",
    "\n",
    "test2_return = column_stemmatizer(test2['test_text'])\n",
    "\n",
    "print(test2_return)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
